---
layout: post
title: "DBDB： Dog Bed Database"
tags: [Translation, Database]
---

[翻译]DBDB： Dog Bed Database

* 目录
{:toc .toc}
---

# DBDB： Dog Bed Database

## Introduction

DBDB是由Pythhon实现的键值数据库（key/value database）。

DBDB旨在解决电脑死机、异常等状况下数据未被保存而丢失的问题。同时DBDB也避免一次性将所有数据放在RAM中，从而能够存入大于RAM容量的数据。

从数据库的ACID[^ACID] (atomicity[^Atomic], consistency[^Consistency], isolation[^Isolation], and durability[^Durability])四个属性来看：

- DBDB的数据更新方式具有原子性和持久性，但因没有对储存数据进行限制，所以无法提供一致性，另外独立性也并未实现。

- 应用程序的代码当然可以保证自己的一致性，但是实现独立性需要一个transaction manager。 DBDB并没有在这方面进行涉足（关于transaction manageer在[CircleDB chapter](http://aosabook.org/en/500L/an-archaeology-inspired-database.html) 有详细介绍）。

- 从系统维护的角度看，DBDB并不会对Stale data进行资源回收，因不断地更新数据最终会消耗所有的磁盘空间。具体办法可参考[PostgreSQL](http://www.postgresql.org/)的"vacuuming"（循环利用旧的row space）以及[CouchDB](http://couchdb.apache.org/)的"compaction" （by rewriting the "live" parts of the data into a new file, and atomically moving it over the old one）。



## The Architecture of DBDB

* 数据于磁盘的储存

  > "put this on disk somewhere" (how data are laid out in a file; the physical layer)

* 数据的逻辑结构

  > the logical structure of the data (a binary tree in this example; the logical layer)

* 键值对的储存

  > the contents of the key/value store (the association of key `a` to value `foo`; the public API)



## Design

### Organisational Units

从上到下，文件离终端用户越远（越接近底层）。

* `tool.py` 定义了一个命令行工具，用于对数据库进行操作。
* `interface.py` 定义了`DBDB`类，它对底层的`BinaryTree`进行封装，开放Pyton字典接口以供操作。
* `logical.py` 定义了逻辑层，是键值操作的抽象接口。
  - `LogicalBase` provides the API for logical updates (like get, set, and commit) and defers to a concrete subclass to implement the updates themselves. It also manages storage locking and dereferencing internal nodes.
  - `ValueRef` is a Python object that refers to a binary blob[^blob] stored in the database. The indirection lets us avoid loading the entire data store into memory all at once.
* `binary_tree.py` 定义了逻辑街口下具体的二叉树算法。
  - `BinaryTree` provides a concrete implementation of a binary tree, with methods for getting, inserting, and deleting key/value pairs. `BinaryTree` represents an immutable tree; updates are performed by returning a new tree which shares common structure with the old one.
  - `BinaryNode` implements a node in the binary tree.
  - `BinaryNodeRef` is a specialised `ValueRef` which knows how to serialise and deserialise a `BinaryNode`.
* `physical.py` 定义了物理层。
  * `Storage` class provides persistent, (mostly) append-only record storage.

模块的组织结构是基于以下原则：给予每个类以单独的责任。换句话说，每一个类都只能有唯一的修改的理由。



## Code

### Reading a Value

从最简单的在数据库中读取值开始：

`$ python -m dbdb.tool example.db get foo`

1. 这个命令调用的是tool模块中的`main()`

```python
# dbdb/tool.py
def main(argv):
	if not (4 <= len(argv) <= 5):
		usage()
		return BAD_ARGS
	dbname, verb, key, value = (argv[1:] + [None])[:4]
	if verb not in {'get', 'set', 'delete'}:
		usage()
		return BAD_ARGS
    # 连接数据库
	db = dbdb.connect(dbname)			
	try:
		if verb == 'get':
            # 用python字典的方式以key读取value
			sys.stdout.write(db[key])	
		elif verb == 'set':
			db[key] = value
			db.commit()
		else:
			del db[key]
			db.commit()
	except KeyError:
		print("Key not found", file=sys.stderr)
		return BAD_ARGS
	return OK
```

2. `connect()`用于打开数据库（如果不存在则创建一个，但不会覆盖已有的），返回`DBDB`类的实例。

```python
# dbdb/__init__.py
def connect(dbname):
	try:
		f = open(dbname, 'r+b')
	except IOError:
		# os.O_RDWR - open for reading and writing
		# os.O_CREAT − create file if it does not exist
		fd = os.open(dbname, os.O_RDWR | os.O_CREAT)  
		f = os.fdopen(fd, 'r+b')
	return DBDB(f)
```

*备注：open[^1], os.open[^2], os.fdopen[^3]的差别：[link](https://stackoverflow.com/questions/15039528/what-is-the-difference-between-os-open-and-os-fdopen-in-python)。这里使用os.open和fdopen主要作用是当dbname不存在时创建并读取。*

3. `DBDB`中可看到，含有一个对`Storage`实例的引用`_storage`，并传递给`BinaryTree`的实例`_tree`。

***The question of which objects "own" a resource is often an important one in a design, because it gives us hints about what changes might be unsafe***

不直接用`self._tree`接收`Stroage`的实例的理由之一是增强前置条件的控制：通过`_assert_not_closed()`确保database处于未上锁状态。

```python
# dbdb/interface.py
class DBDB(object):
# ...
	def __init__(self, f):
        # 封装数据库文件，提供对数据库文件的操作
		self._storage = Stroage(f)
        # 封装二叉树结构，提供键值操作
		self._tree = BinaryTree(self._storage)

    def __getitem__(self, key):
		self._assert_not_closed()
		return self._tree.get(key)

	def _assert_not_closed(self):
		if self._storage.closed:
			raise ValueError('Database closed.')
```

4. db[key]触发`_tree.get(key)`的调用，`get()`由`LogicalBase`提供。

   `get()`首先检查`_storage`是否被上锁。

* 当处于非上锁状态时，`_refresh_tree_ref()` 将数据树的视图（view）刷新为磁盘中现有的状态，让我们得以读取最新的数据
* 当处于上锁组状态时，意味着其它进程可能正在对被请求读取的数据进行修改，被请求数据很可能不是最新的。这种读取亦被称为`dirty read`。这种模式允许多个使用者在获取数据时无需担心 *blocking*，代价只是稍稍有点out-of-date。

```python
# dbdb/logical.py
# ...
class LogicalBase(object):

    def get(self, key):
        # 如果数据库文件未被上锁，则更新对树的引用
        if not self._storage.locked:
            self._refresh_tree_ref()
        return self._get(self.follow(self._tree_ref), key)

    def _refresh_tree_ref(self):
        self._tree_ref = self.node_ref_class(
            address=self._storage.get_root_address())
```

5. 随后调用的是`BinaryTree`中的`_get()`方法。可看到这里使用的是标准的二叉树搜索方法，并以`_follow()`获取被引用的具体对象（node或value）。

>  We know from reading the `BinaryTree` documentation that `Node`s and `NodeRef`s are value objects: they are immutable and their contents never change. `Node`s are created with an associated key and value, and left and right children. Those associations also never change. The content of the whole `BinaryTree` only visibly changes when the root node is replaced. This means that we don't need to worry about the contents of our tree being changed while we are performing the search.

一旦与键对应的值被找到，将会被返回给`mian()`后写入`stdout`输出，不会作任何添加，以保证数据的准确性。

```python
# dbdb/binary_tree.py
class BinaryTree(LogicalBase):
# ...
	def _get(self, node, key):
		while node is not None:
			if key < node.key:
				node = self._follow(node.left_ref)
			elif node.key < key:
				node = self._follow(node.right_ref)
			else:
				return self._follow(node.value_ref)
		raise KeyError
```



### Inserting and Updating

给键foo设置值bar，命令行语句：

`$ python -m dbdb.tool example.db set foo bar`

1. 同样首先调用`dbdb.tool`的`main()`。由于只是上文重复，以下只标明相关的代码。

```python
# dbdb/tool.py
def main(argv):
# ...
	db = dbdb.connect(dbname)			# CONNECT
	try:
# ...
		elif verb == 'set':
			db[key] = value				# SET VALUE
			db.commit()					# COMMIT
# ...
	except KeyError:
# ...

```

2. `db[key] = value`调用`DBDB.__setitem__()`:

```python
# dbdb/interface.py
class DBDB(object):
# ...
    def __setitem__(self, key, value):
        self._assert_not_closed()
        return self._tree.set(key, value)
```

与`__getitem__`类似，`__setitem__`会先确保数据库处于开放状态，再通过`_tree.set()`将value与	key关联起来。

3. `_tree.set()`来源于`LogicalBase`：

```python
# dbdb/logical.py
class LogicalBase(object):
# ...
    def set(self, key, value):
        if self._storage.lock():
            self._refresh_tree_ref()
        self._tree_ref = self._insert(
            self._follow(self._tree_ref), key, self.value_ref_class(value))
```

首先检查storage lock:

```python
# dbdb/storage.py
class Storage(object):
    # ...
    def lock(self):
        if not self.locked:
            portalocker.lock(self._f, portalocker.LOCK_EX)
            self.locked = True
            return True
        else:
            return False
```

- 可看到，这个锁lock()是由第三方库*potalocker*提供的。

- 如果数据库处于关闭状态，lock()返回`False`，否则利用potalocer上锁，并返回`True`。

  回到`_tree.set()`，首先检查`self._storage.lock()`的返回值的理由是：调用`_refresh_tree_ref`以获得最新的根节点引用，防止我们错过其他进程在我们最后一次刷新磁盘之后做出的改动。随后，`set()`将原有的树替换成含有更新后的键值对的树。

4. 插入或者更新数据树并不会改变任何的节点，因为`_insert()`返回的是新的树。新的树拥有与原来数据树一样的未修改部分（注意，插入的新节点会影响父节点及以上所有节点的child node引用，因此所有受影响节点都需要克隆出新的节点），以节省内存和运行时间。自然地，代码会编写成递归的形式：

```python
# dbdb/binary_tree.py
class BinaryTree(LogicalBase):
# ...
    def _insert(self, node, key, value_ref):
        # 空树或搜索到达终点
        if node is None:
            new_node = BinaryNode(
                self.node_ref_class(), key, value_ref, self.node_ref_class(), 1)
        elif key < node.key:
            # 搜索过程中遍历到的节点，都会以原有信息为基础并修改child node，克隆出新的节点
            new_node = BinaryNode.from_node(
                node,
                left_ref=self._insert(
                    self._follow(node.left_ref), key, value_ref))
        elif node.key < key:
            new_node = BinaryNode.from_node(
                node,
                right_ref=self._insert(
                    self._follow(node.right_ref), key, value_ref))
        else:
            # 搜索结束，获取value_ref引用的value
            new_node = BinaryNode.from_node(node, value_ref=value_ref)
        # 返回节点的引用，address为None，说明新节点未被储存
        return self.node_ref_class(referent=new_node)
```

注意最后返回的是包裹在`NodeRef`中的一个新节点。由于新的节点与原有节点只是共享未受影响的子树，原有的树不会发生变化。这个特性让这个二叉树的数据结构具有不可变的特性(immutable)。

5. 你可能注意到，目前为止还没有对磁盘上的数据产生任何影响。要让以上所做修改反映到磁盘上，需要调用 `commit()`:

> Committing involves writing out all of the dirty state in memory, and then saving the disk address of the tree's new root node.

```python
# dbdb/interface.py
class DBDB(object):
# ...
    def commit(self):
        self._assert_not_closed()
        self._tree.commit()
```

`_tree.commit()`来自`LogicalBase`：

```python
# dbdb/logical.py
class LogicalBase(object):
# ...
    def commit(self):
        # 存储树的引用
        self._tree_ref.store(self._storage)
        # 更新树的根节点地址
        self._storage.commit_root_address(self._tree_ref.address)
```

6. 所有的`NodeRef`先通过`prepare_to_store()`将子节点(Children)序列化[^serialization]，从而将自己序列化到硬盘中。

```python
# dbdb/logical.py
class ValueRef(object):
# ...
    def store(self, storage):
        # 引用对象不为空，地址为空，说明引用还未被储存过
        if self._referent is not None and not self._address:
            # Hook function
            self.prepare_to_store(storage)
            # 获得引用的地址
            self._address = storage.write(self.referent_to_string(self._referent))
```

这个例子中，由于 `LogicalBase`中的`self._tree_ref` 是`BinaryNodeRef` 的一个实例，`BinaryNodeRef` 继承自`ValueRef`并重写了`prepare_to_store()`:

```python
# dbdb/logical.py
class BinaryNodeRef(ValueRef):
    def prepare_to_store(self, storage):
        # 这里的_referent为被引用的节点，如果不含referent说明是未包裹节点的空引用
        if self._referent:
            # 调用BinaryNode的store_refs()方法
            self._referent.store_refs(storage)
```

随之调用 `BinaryNode` 的`store_refs()`:

```python
# dbdb/binary_tree.py
class BinaryNode(object):
# ...
	# 先序遍历整个二叉树
    def store_refs(self, storage):
        self.value_ref.store(storage)  # 录入节点中未登陆的值（修改键值对无需修改节点地址等信息）
        self.left_ref.store(storage)   # 递归直至遇到叶子节点（左右孩子的引用均为None，停止递归）
        self.right_ref.store(storage)  # 未登陆的节点引用将被录入
```

回到`ValueRef`的`store()`方法，store的最后一步是将引用序列化并获得地址`_address`：

```python
# dbdb/logical.py
class ValueRef(object):
# 与上文一致
    def store(self, storage):
        if self._referent is not None and not self._address:
            self.prepare_to_store(storage)
            self._address = storage.write(self.referent_to_string(self._referent))
```

这时候，`NodeRef `的引用节点`_referent` 中，它自己的所有引用都必然含有各自的地址属性，所以我们可以通过创建一个字符串来序列化这个节点:

```python
# dbdb/binary_tree.py
class BinaryNodeRef(ValueRef):
# ...
    @staticmethod
    def referent_to_string(referent):
        return pickle.dumps({
            'left': referent.left_ref.address,
            'key': referent.key,
            'value': referent.value_ref.address,
            'right': referent.right_ref.address,
            'length': referent.length,
        })
```

> Updating the address in the `store()` method is technically a mutation of the `ValueRef`. Because it has no effect on the user-visible value, we can consider it to be immutable.

7. 回到上面的`LogicalBase.commit()`，一旦`store()` 完成对根节点`_tree_ref`的保存，所有的数据都被写到磁盘中，现在可以将根节点地址提交了：

```python
# dbdb/physical.py
class Storage(object):
# ...
    def commit_root_address(self, root_address):
        self.lock()
        self._f.flush()
        self._seek_superblock()
        self._write_integer(root_address)
        self._f.flush()
        self.unlock()
```

> We ensure that the file handle is flushed[^flush()] (so that the OS knows we want all the data saved to stable storage like an SSD) and write out the address of the root node. We know this last write is atomic because we store the disk address on a sector boundary. It's the very first thing in the file, so this is true regardless of sector size, and single-sector disk writes are guaranteed to be atomic by the disk hardware.

由于根节点地址要不是旧的要不就时新的，不会处于两者之间，其他进程可以对数据库进行读取时不会遇到任何的锁。一个外部进程可能看到的是老的或新的树，但永远不会看到两者的混合。在这种意义上，提交（commits）也是原子性的。

> Because we write the new data to disk and call the `fsync` [syscall](http://aosabook.org/en/500L/dbdb-dog-bed-database.html#fn2) before we write the root node address, uncommitted data are unreachable. Conversely, once the root node address has been updated, we know that all the data it references are also on disk. In this way, commits are also durable.

We're done!



### Deleting

删除的代码实现类似于插入，最终调用的`_delete()`如下：

```python
# dbdb/binary_tree.py

class BinaryTree(LogicalBase):
# ...
    def _delete(self, node, key):
        if node is None:
            raise KeyError
        elif key < node.key:
            new_node = BinaryNode.from_node(
                node,
                left_ref=self._delete(
                    self._follow(node.left_ref), key))
        elif node.key < key:
            new_node = BinaryNode.from_node(
                node,
                right_ref=self._delete(
                    self._follow(node.right_ref), key))
        else:
            left = self._follow(node.left_ref)
            right = self._follow(node.right_ref)
            # 情况1:待删除节点含有左右孩子
            if left and right:
                # replacement节点为原节点的直接前继，用它替换被删除节点
                replacement = self._find_max(left)
                # 被删除节点右子树维持不变
                # 左孩子树，需要把原replacement节点删除，只需要和它的左孩子交换即可
                left_ref = self._delete(
                    self._follow(node.left_ref), replacement.key)
                new_node = BinaryNode(
                    left_ref,
                    replacement.key,
                    replacement.value_ref,
                    node.right_ref,
                    left_ref.length + node.right_ref.length + 1,
                )
            elif left:
                # 情况2:待删除节点含有左孩子
                return node.left_ref
            else:
                # 情况3:待删除节点含有右孩子或不含任何孩子
                return node.right_ref
        return self.node_ref_class(referent=new_node)

    def _find_max(self, node):
        while True:
            next_node = self._follow(node.right_ref)
            if next_node is None:
                return node
            node = next_node
```





## How NodeRefs Save Memory

为避免将整棵树的数据同时放在内存中，当一个逻辑节点被人从磁盘中读取时，它的左孩子及右孩子与值的磁盘地址也一同被加载到内存中。调用`NodeRef.get()`就能对它们去引用，获得所包裹的数据（值或节点）。

All we need to construct a `NodeRef` is an address:

```
+---------+
| NodeRef |
| ------- |
| addr=3  |
| get()   |
+---------+
```

Calling `get()` on it will return the concrete node, along with that node's references as `NodeRef`s:

```
+---------+     +---------+     +---------+
| NodeRef |     | Node    |     | NodeRef |
| ------- |     | ------- | +-> | ------- |
| addr=3  |     | key=A   | |   | addr=1  |
| get() ------> | value=B | |   +---------+
+---------+     | left  ----+
                | right ----+   +---------+
                +---------+ |   | NodeRef |
                            +-> | ------- |
                                | addr=2  |
                                +---------+
```

> When changes to the tree are not committed, they exist in memory with references from the root down to the changed leaves. The changes aren't saved to disk yet, so the changed nodes contain concrete keys and values and no disk addresses. The process doing the writing can see uncommitted changes and can make more changes before issuing a commit, because `NodeRef.get()` will return the uncommitted value if it has one; there is no difference between committed and uncommitted data when accessed through the API. All the updates will appear atomically to other readers because changes aren't visible until the new root node address is written to disk. Concurrent updates are blocked by a lockfile on disk. The lock is acquired on first update, and released after commit.



### Exercises for the Reader

DBDB allows many processes to read the same database at once without blocking; the tradeoff is that readers can sometimes retrieve stale data. What if we needed to be able to read some data consistently? A common use case is reading a value and then updating it based on that value. How would you write a method on `DBDB` to do this? What tradeoffs would you have to incur to provide this functionality?

The algorithm used to update the data store can be completely changed out by replacing the string `BinaryTree` in `interface.py`. Data stores tend to use more complex types of search trees such as B-trees, B+ trees, and others to improve the performance. While a balanced binary tree (and this one isn't) needs to do $O(log2(n))$ random node reads to find a value, a B+ tree needs many fewer, for example $O(log32(n))$ because each node splits 32 ways instead of just 2. This makes a huge different in practice, since looking through 4 billion entries would go from $log2(232)=32$ to $log32(232)≈6.4$lookups. Each lookup is a random access, which is incredibly expensive for hard disks with spinning platters. SSDs help with the latency, but the savings in I/O still stand.

By default, values are stored by `ValueRef` which expects bytes as values (to be passed directly to `Storage`). The binary tree nodes themselves are just a sublcass of `ValueRef`. Storing richer data via [json](http://json.org/) or [msgpack](http://msgpack.org/) is a matter of writing your own and setting it as the `value_ref_class`. `BinaryNodeRef` is an example of using [pickle](https://docs.python.org/3.4/library/pickle.html) to serialise data.

Database compaction is another interesting exercise. Compacting can be done via an infix-of-median traversal of the tree writing things out as you go. It's probably best if the tree nodes all go together, since they're what's traversed to find any piece of data. Packing as many intermediate nodes as possible into a disk sector should improve read performance, at least right after compaction. There are some subtleties here (for example, memory usage) if you try to implement this yourself. And remember: always benchmark performance enhancements before and after! You'll often be surprised by the results.



[^1]: [Open file and return a corresponding file object](https://docs.python.org/3/library/functions.html#open)
[^2]: [open the file path and .... Return the file descriptor](https://docs.python.org/3/library/os.html#os.open)
[^3]: [Return an open file object connected to the file descriptor fd. This is an alias of the open() built-in function and accepts the same arguments. The only difference is that the first argument of fdopen() must always be an integer.](https://docs.python.org/3/library/os.html#os.fdopen)				
[^serialization]: [serialization is the process of translating data structures or object state into a format that can be stored (for example, in a file or memory buffer) or transmitted (for example, across a network connection link) and reconstructed later (possibly in a different computer environment). When the resulting series of bits is reread according to the serialization format, it can be used to create a semantically identical clone of the original object.](https://en.wikipedia.org/wiki/Serialization)		
[^super  block]: [用于记录文件系统的整体信息，长度一般设置为1024 B的整数倍。](https://unix.stackexchange.com/questions/4402/what-is-a-superblock-inode-dentry-and-a-file)		 
[^blob]: [Binary large object](https://en.wikipedia.org/wiki/Binary_large_object)
[^ACID]: [(Atomicity, Consistency, Isolation, Durability) is a set of properties of database transactions intended to guarantee validity even in the event of errors, power failures, etc.](https://en.wikipedia.org/wiki/ACID_(computer_science))
[^Atomic]: [整个transaction作不可分割的一个整体，其中某一部分失败即整体失败（如原子版不可分割）](https://en.wikipedia.org/wiki/Atomicity_(database_systems)) 
[^Consistency]: [指每次transaction不可改变数据库的有效状态，每一写入数据库的数据必须遵循已制定的规则。保证数据库不被非法transaction污染（但不能保证transaction一定正确）](https://en.wikipedia.org/wiki/Consistency_(database_systems))
[^Isolation]: [Isolation](https://en.wikipedia.org/wiki/Isolation_(database_systems))
[^Durability]: [指transaction一旦被提交，即使遇到系统错误如宕机也能完成提交（通常指transaction被记录在non-voilatile memory中）](https://en.wikipedia.org/wiki/Durability_(database_systems))
[^handle]: [an abstract reference to a resource.](https://en.wikipedia.org/wiki/Handle_(computing))
[^Reference]: [a value that enables a program to indirectly access a particular datum, such as a variable's value or a record, in the computer's memory or in some other storage device.](https://en.wikipedia.org/wiki/Reference_(computer_science))
[^flush()]: [将缓冲区里的字节数据写进文件对象](https://stackoverflow.com/questions/7127075/what-exactly-the-pythons-file-flush-is-doing/7127201) 